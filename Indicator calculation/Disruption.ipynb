{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import gc\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file):\n",
    "\n",
    "    r = open(file,'rb')\n",
    "    x = pickle.load(r)\n",
    "    r.close()\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(x,file):\n",
    "\n",
    "    r = open(file,'wb')\n",
    "    pickle.dump(x,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Theorem data\n",
    "list_all = pd.read_excel('F:\\\\dataset\\\\mpeuni\\\\Theorems\\\\new\\\\nodelist_all.xlsx', header = 0)\n",
    "adjacency_listT = pd.read_excel('F:\\\\dataset\\\\mpeuni\\\\Theorems\\\\new\\\\adjacency_list_Theorems_and_Axioms_only.xlsx', header = 0)\n",
    "F = nx.from_pandas_edgelist(adjacency_listT, 'Theorem_id', 'Ref_id', create_using=nx.DiGraph())\n",
    "F2 = F.reverse(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import other data\n",
    "name1 = 'XXX.pkl'\n",
    "Fdata = load_file(name1)\n",
    "F2 = F.reverse(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist = list(F)\n",
    "topological_generationsTGM = [sorted(generation) for generation in nx.topological_generations(F2)]\n",
    "generation = []\n",
    "for k in range(len(nodelist)):\n",
    "    pindex = []\n",
    "    for p in range(len(topological_generationsTGM)):\n",
    "        pindex.append(nodelist[k] in topological_generationsTGM[p])\n",
    "    p1 = pindex.index(True)\n",
    "    generation.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disruption = []\n",
    "njcount = []\n",
    "nicount = []\n",
    "nkcount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3504998ac7e44f6b99047f905fefdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(nodelist))):\n",
    "    p1 = generation[i]\n",
    "    node_index = nodelist.index\n",
    "    neighbors_F2 = list(F2.neighbors(nodelist[i]))\n",
    "    neighbors_F = list(F.neighbors(nodelist[i]))\n",
    "\n",
    "    neighbor1 = [neighbor for neighbor in neighbors_F2 if generation[node_index(neighbor)] < p1 + 11]\n",
    "\n",
    "    neighbor3_1 = list(itertools.chain.from_iterable(list(F2.neighbors(neighbor)) for neighbor in neighbors_F))\n",
    "    nj = set(neighbor3_1).intersection(neighbor1)\n",
    "    ni = set(neighbor1).difference(nj)\n",
    "    nicount.append(len(ni))\n",
    "    njcount.append(len(nj))\n",
    "\n",
    "    nk = [nkor_node for nkor_node in set(neighbor3_1).difference(nj) if p1 < generation[node_index(nkor_node)] < p1 + 11]\n",
    "    nkcount.append(len(nk))\n",
    "    \n",
    "    total_neighbors = len(ni) + len(nj) + len(nk)\n",
    "    \n",
    "    if total_neighbors==0:\n",
    "        Disruptionx = None\n",
    "    else:\n",
    "        Disruptionx = (len(ni)-len(nj))/total_neighbors\n",
    "    Disruption.append(Disruptionx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disruptiondata = pd.DataFrame({'Generation':generation, 'Disruption':Disruption, 'nj':njcount, 'ni':nicount, 'nk':nkcount}, index=nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_distribution(F):\n",
    "    degree = pd.DataFrame(nx.degree(F))\n",
    "    degree = degree.sort_values(by=[1], ascending=False)\n",
    "    citypdf_sum2 = pd.DataFrame(degree[1].value_counts())\n",
    "    citypdf_sum2['f'] = citypdf_sum2.index\n",
    "    citypdf_sum2['频率'] = citypdf_sum2[1]/citypdf_sum2[1].sum()\n",
    "    citypdf_sum2 = citypdf_sum2.sort_values(by=['f'], ascending=True)\n",
    "    ccdf_sum2 = np.zeros(len(citypdf_sum2))\n",
    "    for i in range(len(ccdf_sum2)):\n",
    "        ccdf_sum2[i] = 1-np.sum(citypdf_sum2.values[0:i,2])\n",
    "    citypdf_sum2['ccdf'] = ccdf_sum2\n",
    "    gdo = pd.DataFrame(F.out_degree())\n",
    "    gdo = gdo.sort_values(by=[1], ascending=False)\n",
    "    citypdf_sum = pd.DataFrame(gdo[1].value_counts())\n",
    "    citypdf_sum['f'] = citypdf_sum.index\n",
    "    citypdf_sum['频率'] = citypdf_sum[1]/citypdf_sum[1].sum()\n",
    "    citypdf_sum = citypdf_sum.sort_values(by=['f'], ascending=True)\n",
    "    ccdf_sum = np.zeros(len(citypdf_sum))\n",
    "    for i in range(len(ccdf_sum)):\n",
    "        ccdf_sum[i] = 1-np.sum(citypdf_sum.values[0:i,2])\n",
    "    citypdf_sum['ccdf'] = ccdf_sum\n",
    "    gdi = pd.DataFrame(F.in_degree())\n",
    "    gdi = gdi.sort_values(by=[1], ascending=False)\n",
    "    citypdf_sum1 = pd.DataFrame(gdi[1].value_counts())\n",
    "    citypdf_sum1['f'] = citypdf_sum1.index\n",
    "    citypdf_sum1['频率'] = citypdf_sum1[1]/citypdf_sum1[1].sum()\n",
    "    citypdf_sum1 = citypdf_sum1.sort_values(by=['f'], ascending=True)\n",
    "    ccdf_sum1 = np.zeros(len(citypdf_sum1))\n",
    "    for i in range(len(ccdf_sum1)):\n",
    "        ccdf_sum1[i] = 1-np.sum(citypdf_sum1.values[0:i,2])\n",
    "    citypdf_sum1['ccdf'] = ccdf_sum1\n",
    "    degree.set_index([0], inplace=True)\n",
    "    gdo.set_index([0], inplace=True)\n",
    "    gdi.set_index([0], inplace=True)\n",
    "    degree_all = pd.concat([degree, gdo, gdi], axis=1)\n",
    "    degree_all.columns = ['Degree','Out-degree','In-degree']\n",
    "    return degree_all, citypdf_sum2, citypdf_sum, citypdf_sum1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTGMdegree_all, FTGMdegreepdf, FTGMoutdegreepdf, FTGMindegreepdf = degree_distribution(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disruptiondata = pd.merge(Disruptiondata, FTGMdegree_all, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disruptiondata['Citation'] = Disruptiondata['ni'] + Disruptiondata['nj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disruptiondata['Clustering'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2 = 'Disruptiondata10XXX.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(Disruptiondata,name2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
